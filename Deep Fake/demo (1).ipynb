{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"cdO_RxQZLahB"},"source":["# Demo for paper \"First Order Motion Model for Image Animation\""]},{"cell_type":"markdown","metadata":{"id":"GCDNKsEGLtR6"},"source":["**Clone repository**"]},{"cell_type":"code","metadata":{"id":"UCMFMJV7K-ag","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8706da93-18b2-43a4-97ff-3597b7a25e0f","executionInfo":{"status":"ok","timestamp":1672726227925,"user_tz":-330,"elapsed":7601,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["!git clone https://github.com/AliaksandrSiarohin/first-order-model"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'first-order-model'...\n","remote: Enumerating objects: 337, done.\u001b[K\n","remote: Counting objects: 100% (31/31), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 337 (delta 15), reused 19 (delta 7), pack-reused 306\u001b[K\n","Receiving objects: 100% (337/337), 72.16 MiB | 12.91 MiB/s, done.\n","Resolving deltas: 100% (173/173), done.\n"]}]},{"cell_type":"code","metadata":{"id":"PBp6l_4bBYUL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a2cf38ae-b0d2-4c45-e781-bd98cebee8f0","executionInfo":{"status":"ok","timestamp":1672726227926,"user_tz":-330,"elapsed":32,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["cd first-order-model"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/first-order-model/first-order-model\n"]}]},{"cell_type":"markdown","metadata":{"id":"IcMX7ueZO0Oa"},"source":["**Mount your Google drive folder on Colab**"]},{"cell_type":"code","metadata":{"id":"tDbMA8R9OuUo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"15468a26-a722-40b9-8f36-10c839836639","executionInfo":{"status":"ok","timestamp":1672726231108,"user_tz":-330,"elapsed":3202,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install imageio-ffmpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4WILY2qP7Gf","executionInfo":{"status":"ok","timestamp":1672726234798,"user_tz":-330,"elapsed":3698,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}},"outputId":"a85786b4-b492-4a6c-ef03-bb00883bff50"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.8/dist-packages (0.4.7)\n"]}]},{"cell_type":"markdown","metadata":{"id":"VsgVK1EURXkd"},"source":["**Add folder https://drive.google.com/drive/folders/1kZ1gCnpfU0BnpdU47pLM_TQ6RypDDqgw?usp=sharing  to your google drive.\n","Alternativelly you can use this mirror link https://drive.google.com/drive/folders/16inDpBRPT1UC0YMGMX3dKvRnOUsf5Dhn?usp=sharing**"]},{"cell_type":"markdown","metadata":{"id":"rW-ipQXPOWUo"},"source":["**Load driving video and source image**"]},{"cell_type":"code","metadata":{"id":"Oxi6-riLOgnm","colab":{"base_uri":"https://localhost:8080/","height":373},"outputId":"31bd45a6-13fe-4d69-b097-9190cc92a6cc","executionInfo":{"status":"error","timestamp":1672726236340,"user_tz":-330,"elapsed":1559,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["import imageio\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from skimage.transform import resize\n","from IPython.display import HTML\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","source_image = imageio.imread('/content/gdrive/MyDrive/ipnb/deepfake/first-order-motion-model/K0004.jfif')\n","driving_video = imageio.mimread('/content/gdrive/MyDrive/ipnb/deepfake/first-order-motion-model/video.mp4')\n","\n","\n","#Resize image and video to 256x256\n","\n","source_image = resize(source_image, (256, 256))[..., :3]\n","driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n","\n","def display(source, driving, generated=None):\n","    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n","\n","    ims = []\n","    for i in range(len(driving)):\n","        cols = [source]\n","        cols.append(driving[i])\n","        if generated is not None:\n","            cols.append(generated[i])\n","        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n","        plt.axis('off')\n","        ims.append([im])\n","\n","    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n","    plt.close()\n","    return ani\n","    \n","\n","HTML(display(source_image, driving_video).to_html5_video())"],"execution_count":19,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e2cc834eaebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msource_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/ipnb/deepfake/first-order-motion-model/K0004.jfif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdriving_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/ipnb/deepfake/first-order-motion-model/video.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mmimread\u001b[0;34m(uri, format, memtest, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnbyte_limit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnbytes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnbyte_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# clear to free the memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0;34m\"imageio.mimread() has read over {}B of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;34m\"image data.\\nStopped to avoid memory problems.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: imageio.mimread() has read over 256000000B of image data.\nStopped to avoid memory problems. Use imageio.get_reader(), increase threshold, or memtest=False"]}]},{"cell_type":"markdown","metadata":{"id":"xjM7ubVfWrwT"},"source":["**Create a model and load checkpoints**"]},{"cell_type":"code","metadata":{"id":"3FQiXqQPWt5B","executionInfo":{"status":"aborted","timestamp":1672726236344,"user_tz":-330,"elapsed":32,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["#!pip install ffmpeg\n","from demo import load_checkpoints\n","generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', \n","                            checkpoint_path='/content/gdrive/MyDrive/ipnb/deepfake/first-order-motion-model/vox-adv-cpk.pth.tar')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fdFdasHEj3t7"},"source":["**Perform image animation**"]},{"cell_type":"code","metadata":{"id":"SB12II11kF4c","executionInfo":{"status":"aborted","timestamp":1672726236346,"user_tz":-330,"elapsed":34,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["from demo import make_animation\n","from skimage import img_as_ubyte\n","\n","predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n","\n","#save resulting video\n","imageio.mimsave('../generated2.mp4', [img_as_ubyte(frame) for frame in predictions])\n","#video can be downloaded from /content folder\n","\n","HTML(display(source_image, driving_video, predictions).to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-tJN01xQCpqH"},"source":["**In the cell above we use relative keypoint displacement to animate the objects. We can use absolute coordinates instead,  but in this way all the object proporions will be inherited from the driving video. For example Putin haircut will be extended to match Trump haircut.**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"fg77g-uzPc5-","executionInfo":{"status":"aborted","timestamp":1672726236348,"user_tz":-330,"elapsed":34,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOE_W_kfC9aX","executionInfo":{"status":"aborted","timestamp":1672726236349,"user_tz":-330,"elapsed":35,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=False, adapt_movement_scale=True)\n","HTML(display(source_image, driving_video, predictions).to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QnXrecuX6_Kw"},"source":["## Running on your data\n","\n","**First we need to crop a face from both source image and video, while simple graphic editor like paint can be used for cropping from image. Cropping from video is more complicated. You can use ffpmeg for this.**"]},{"cell_type":"code","metadata":{"id":"brJlA_5o72Xc","executionInfo":{"status":"aborted","timestamp":1672726236350,"user_tz":-330,"elapsed":35,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["!ffmpeg -i /content/gdrive/My\\ Drive/first-order-motion-model/07.mkv -ss 00:08:57.50 -t 00:00:08 -filter:v \"crop=600:600:760:50\" -async 1 hinton.mp4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NSHSxV8iGybI"},"source":["**Another posibility is to use some screen recording tool, or if you need to crop many images at ones use face detector(https://github.com/1adrianb/face-alignment) , see https://github.com/AliaksandrSiarohin/video-preprocessing for preprcessing of VoxCeleb.** "]},{"cell_type":"code","metadata":{"id":"d8kQ3U7MHqh-","executionInfo":{"status":"aborted","timestamp":1672726236351,"user_tz":-330,"elapsed":36,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"source":["source_image = imageio.imread('/content/gdrive/MyDrive/ipnb/deepfake/first-order-motion-model/01.png')\n","driving_video = imageio.mimread('/content/gdrive/MyDrive/ipnb/deepfake/first-order-motion-model/obama.mp4', memtest=False)\n","\n","\n","#Resize image and video to 256x256\n","\n","source_image = resize(source_image, (256, 256))[..., :3]\n","driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n","\n","predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True,\n","                             adapt_movement_scale=True)\n","\n","HTML(display(source_image, driving_video, predictions).to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imageio.mimsave('../generated4.mp4', [img_as_ubyte(frame) for frame in predictions])"],"metadata":{"id":"pwQKBS-5x3-b","executionInfo":{"status":"aborted","timestamp":1672726236352,"user_tz":-330,"elapsed":37,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V2voXoyI0l8c","executionInfo":{"status":"aborted","timestamp":1672726236356,"user_tz":-330,"elapsed":41,"user":{"displayName":"Arun Maitexa","userId":"15891683634873394654"}}},"execution_count":null,"outputs":[]}]}